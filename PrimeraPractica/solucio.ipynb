{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a64338",
   "metadata": {},
   "source": [
    "# Pràctica 1 - El procés de l'aprenentatge automàtic {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34994773",
   "metadata": {},
   "source": [
    "**Autors:**  Marc Melia Flexas y Martin Mitrovski Delov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dff480",
   "metadata": {},
   "source": [
    "## Taula de continguts {-}\n",
    "\n",
    " 1. [Introducció](#introduccio)\n",
    " 2. [Tractament de dades](#tractament)\n",
    " 3. [Experiments realitzats](#experiments)\n",
    " 4. [Anàlisi dels resultats](#analisi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a22faf",
   "metadata": {},
   "source": [
    "# Introducció {#introduccio}\n",
    "\n",
    "El projecte...jhkjhkj\n",
    "\n",
    "El conjunt de dades que utilitzarem és Fashion Mnist\n",
    "\n",
    "**Fashion Mnist**\n",
    "\n",
    "Aquest conjunt de dades conté 70.000 imatges en escala de grisos en 10 categories. Les imatges mostren peces de roba individuals a baixa resolució (28 per 28 píxels). Fashion MNIST està pensat com una evolució directa del conjunt de dades clàssic MNIST que conté digits escrit a mà. Utilitzarem Fashion MNIST perquè presenta un problema una mica més difícil que el MNIST normal. Tots dos conjunts de dades són relativament petits i s'utilitzen per verificar que un algorisme funciona com s'esperava. Són bons punts de partida per provar i depurar codi, el que es coneix com a base line. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def1dee5",
   "metadata": {},
   "source": [
    "## Libreries utilitzades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6cda95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skimage import feature\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba7934a",
   "metadata": {},
   "source": [
    "# Tractament de dades {#tractament}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f368e16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "(10000, 784)\n",
      "(10000,)\n",
      "       pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
      "0           0       0       0       0       0       0       0       0       0   \n",
      "1           0       0       0       0       0       0       0       0       0   \n",
      "2           0       0       0       0       0       0       0       5       0   \n",
      "3           0       0       0       1       2       0       0       0       0   \n",
      "4           0       0       0       0       0       0       0       0       0   \n",
      "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "59995       0       0       0       0       0       0       0       0       0   \n",
      "59996       0       0       0       0       0       0       0       0       0   \n",
      "59997       0       0       0       0       0       0       0       0       0   \n",
      "59998       0       0       0       0       0       0       0       0       0   \n",
      "59999       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "       pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0            0  ...         0         0         0         0         0   \n",
      "1            0  ...         0         0         0         0         0   \n",
      "2            0  ...         0         0         0        30        43   \n",
      "3            0  ...         3         0         0         0         0   \n",
      "4            0  ...         0         0         0         0         0   \n",
      "...        ...  ...       ...       ...       ...       ...       ...   \n",
      "59995        0  ...         0         0         0         0         0   \n",
      "59996        0  ...        73         0         0         0         0   \n",
      "59997        0  ...       160       162       163       135        94   \n",
      "59998        0  ...         0         0         0         0         0   \n",
      "59999        0  ...         0         0         0         0         0   \n",
      "\n",
      "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
      "0             0         0         0         0         0  \n",
      "1             0         0         0         0         0  \n",
      "2             0         0         0         0         0  \n",
      "3             1         0         0         0         0  \n",
      "4             0         0         0         0         0  \n",
      "...         ...       ...       ...       ...       ...  \n",
      "59995         0         0         0         0         0  \n",
      "59996         0         0         0         0         0  \n",
      "59997         0         0         0         0         0  \n",
      "59998         0         0         0         0         0  \n",
      "59999         0         0         0         0         0  \n",
      "\n",
      "[60000 rows x 784 columns]\n"
     ]
    }
   ],
   "source": [
    "# Carregam el conjunt de dades\n",
    "train = pd.read_csv('./dat/fashion-mnist_train.csv')\n",
    "test = pd.read_csv('./dat/fashion-mnist_test.csv')\n",
    "\n",
    "# Separam el conjunt d'entrenament en característiques X_train i etiquetes Y_train\n",
    "X_train= train.drop(['label'],axis = 1)\n",
    "y_train = train['label']\n",
    "\n",
    "# Separam el conjunt de test en característiques X_train i etiquetes Y_train\n",
    "X_test= test.drop(['label'],axis = 1)\n",
    "y_test = test['label']\n",
    "\n",
    "# Dimensió del conjunt de característiques\n",
    "print(X_train.shape)\n",
    "\n",
    "# Dimensió de les etiquetes\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_test.shape)\n",
    "\n",
    "#X_train = X_train.astype('float32')\n",
    "#X_val = X_val.astype('float32')\n",
    "#X_test = X_test.astype('float32')\n",
    "\n",
    "#Normalizar los valores de píxeles dividiéndolos por 255.0\n",
    "#X_train /= 255.0\n",
    "#X_val /= 255.0\n",
    "#X_test /= 255.0\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91ef77fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma original de X_train: (60000, 784)\n",
      "Forma de X_train después de aplicar LBP: (60000, 784)\n",
      "[[16777215. 16777215. 16777215. ... 16777215. 16777215. 16777215.]\n",
      " [16777215. 16777215. 16777215. ... 16777215. 16777215. 16777215.]\n",
      " [16777215. 16777215. 16777215. ... 16777215. 16777215. 16777215.]\n",
      " ...\n",
      " [16777215. 16777215. 16777215. ... 16777215. 16777215. 16777215.]\n",
      " [16777215. 16777215. 16777215. ... 16777215. 16777215. 16777215.]\n",
      " [16777215. 16777215. 16777215. ... 16777215. 16777215. 16777215.]]\n",
      "16777215.0\n"
     ]
    }
   ],
   "source": [
    "# Función para aplicar LBP a una imagen\n",
    "def apply_lbp(image):\n",
    "    # Ajustar la forma de la imagen a (28, 28) si es necesario\n",
    "    image = np.array(image).reshape(28, 28)\n",
    "    \n",
    "\n",
    "    # Aplicar LBP a la imagen\n",
    "    lbp_image = feature.local_binary_pattern(image, P=24, R=3)\n",
    "\n",
    "    # Aplanar la imagen LBP\n",
    "    lbp_image_flat = lbp_image.flatten()\n",
    "    \n",
    "    #print(lbp_image_flat)\n",
    "\n",
    "    return lbp_image_flat\n",
    "\n",
    "# Aplicar LBP a todas las imágenes de entrenamiento y prueba\n",
    "X_train_lbp = np.array([apply_lbp(image) for image in X_train.values])\n",
    "X_test_lbp = np.array([apply_lbp(image) for image in X_test.values])\n",
    "\n",
    "# Verificar las nuevas formas\n",
    "print(\"Forma original de X_train:\", X_train.shape)\n",
    "print(\"Forma de X_train después de aplicar LBP:\", X_train_lbp.shape)\n",
    "\n",
    "#X_train_lbp /= 255.0\n",
    "#X_val /= 255.0\n",
    "#X_test_lbp /= 255.0\n",
    "\n",
    "print(X_train_lbp)\n",
    "\n",
    "print(X_train_lbp[0][0])\n",
    "\n",
    "\n",
    "# Ahora puedes utilizar X_train_lbp y X_test_lbp en lugar de X_train y X_test en tu modelo SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b07d13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma original de X_train: (60000, 784)\n",
      "Forma de X_train después de aplicar LBP: (60000, 392)\n"
     ]
    }
   ],
   "source": [
    "def apply_hog(image):\n",
    "    # Ajustar la forma de la imagen a (28, 28) si es necesario\n",
    "    image = np.array(image).reshape(28, 28)\n",
    "\n",
    "    # Calcular las características HOG\n",
    "    hog_features, hog_image = feature.hog(image, orientations=8, pixels_per_cell=(4, 4),\n",
    "                                          cells_per_block=(1, 1), visualize=True)\n",
    "\n",
    "    # Aplanar las características HOG\n",
    "    hog_features_flat = hog_features.flatten()\n",
    "\n",
    "    return hog_features_flat\n",
    "\n",
    "\n",
    "X_train_hog = np.array([apply_hog(image) for image in X_train.values])\n",
    "X_test_hog = np.array([apply_hog(image) for image in X_test.values])\n",
    "\n",
    "# Verificar las nuevas formas\n",
    "print(\"Forma original de X_train:\", X_train.shape)\n",
    "print(\"Forma de X_train después de aplicar LBP:\", X_train_hog.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2dbecf",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5968f16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 81)\n",
      "(10000, 81)\n",
      "[[ 1.06649729e+01  1.49933635e+01 -6.89468090e-01 ...  2.30535372e-01\n",
      "   9.81395644e-01 -8.84122042e-01]\n",
      " [-1.19897476e+01  1.18127701e+01 -5.80104873e+00 ...  8.67317161e-01\n",
      "  -1.22617381e+00 -5.91727962e-01]\n",
      " [ 2.05176712e+01  1.57978434e+00  6.77012222e+00 ... -1.16864241e-01\n",
      "  -1.48010090e-02 -4.76387998e-01]\n",
      " ...\n",
      " [ 7.14876699e+00 -5.43564927e-01 -8.74059571e-01 ... -6.37226067e-01\n",
      "  -4.69789395e-01  8.86471004e-02]\n",
      " [ 4.43415256e+00  2.08327043e+01 -5.76302113e-01 ...  2.95631752e-01\n",
      "  -2.01054401e+00 -1.37214034e+00]\n",
      " [-9.10680985e+00  1.48311538e+01 -3.67467806e+00 ... -2.03501184e+00\n",
      "  -1.84937814e+00  7.12581912e-01]]\n",
      "[[ 15.98149283  -4.59762206  -1.12973407 ...   1.05773224   1.78713826\n",
      "    0.61097464]\n",
      " [ -1.32965543 -17.28430805  -6.21186681 ...  -0.25380406  -0.50499781\n",
      "   -0.34996485]\n",
      " [ -9.77009012  -3.29941672  11.43858573 ...  -0.31222027   0.53711554\n",
      "   -1.06017376]\n",
      " ...\n",
      " [  4.5119519   10.03817628   4.8921672  ...  -0.33350819  -0.5149351\n",
      "   -0.37858404]\n",
      " [ 19.90629791  17.75176979   0.28420712 ...  -1.91102345   4.50907451\n",
      "    2.80854078]\n",
      " [ 22.62617589  -1.46500113   4.50935393 ...  -0.74300996   0.35994893\n",
      "    0.09071183]]\n"
     ]
    }
   ],
   "source": [
    "# Normalizar StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "#PCA\n",
    "# Especificar el número de componentes principales que deseas retener\n",
    "n_components = 0.85  # Ajusta según tus necesidades\n",
    "\n",
    "# Inicializar PCA\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Ajustar y transformar los datos de entrenamiento\n",
    "X_train_pca = pca.fit_transform(X_train_normalized)\n",
    "\n",
    "# Transformar los datos de prueba (usando los mismos componentes principales aprendidos del conjunto de entrenamiento)\n",
    "X_test_pca = pca.transform(X_test_normalized)\n",
    "\n",
    "print(X_train_pca.shape)\n",
    "print(X_test_pca.shape)\n",
    "\n",
    "print(X_train_pca)\n",
    "print(X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb4ad00",
   "metadata": {},
   "source": [
    "# Experiments realitzats {#experiments}\n",
    "\n",
    "## Experiment 1\n",
    "\n",
    "En el primer experiment que volem realizar volem veure quin és el resultat d'utilitzar un SVM amb els paràmetres per defecte, sense modificarne cap. Els paràmetres per defecte de la classe SVC de la llibreria sklear son els seguents:\n",
    "\n",
    "SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=1e-3, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "\n",
    "-sense normalitzar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9b0d08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de entrenamiento: 248.13191533088684 segundos\n",
      "Accuracy on test set: 0.8921\n"
     ]
    }
   ],
   "source": [
    "# Iniciar el temporizador antes de entrenar el modelo\n",
    "start_time = time.time()\n",
    "\n",
    "# Inicializar el clasificador SVM\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Entrenar el modelo SVM\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Detener el temporizador después de entrenar el modelo\n",
    "end_time = time.time()\n",
    "\n",
    "# Calcular el tiempo transcurrido\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Tiempo de entrenamiento: {elapsed_time} segundos\")\n",
    "\n",
    "y_test_pred = svm_classifier.predict(X_test)\n",
    "    \n",
    "# Evaluar el rendimiento en el conjunto de test\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Accuracy on test set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6f200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    clf = SVC(kernel='linear', C=1)\n",
    "\n",
    "    # Configura k-fold cross-validation\n",
    "    k_fold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "    # Realiza k-fold cross-validation y obtén las puntuaciones de precisión\n",
    "    cross_val_scores = cross_val_score(clf, X_train, y_train, cv=k_fold, scoring='accuracy')\n",
    "\n",
    "    # Imprime las puntuaciones de precisión para cada fold\n",
    "    print(\"Puntuaciones de precisión para cada fold:\", cross_val_scores)\n",
    "\n",
    "    # Imprime la precisión promedio\n",
    "    print(\"Precisión promedio:\", np.mean(cross_val_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290db2ac",
   "metadata": {},
   "source": [
    "Explicar resultats experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3539dc",
   "metadata": {},
   "source": [
    "## Experiment 2\n",
    "\n",
    "GridSearch\n",
    "\n",
    "KFold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32781ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los parámetros y los valores a probar\n",
    "param_grid = {'C': [0.1, 1, 10, 100], \n",
    "              'kernel': ['linear', 'rbf', 'poly','sigmoid'], \n",
    "              'gamma': ['scale', 'auto']}\n",
    "\n",
    "# Inicializar el clasificador  SVM\n",
    "svm_classifier = SVC()  \n",
    "\n",
    "# Inicializar GridSearchCV con el clasificador y los parámetros a probar\n",
    "grid_search = GridSearchCV(estimator=svm_classifier, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Iniciar el temporizador antes de entrenar el modelo\n",
    "start_time = time.time()\n",
    "\n",
    "# Realizar la búsqueda de cuadrícula en los datos\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "# Detener el temporizador después de entrenar el modelo\n",
    "end_time = time.time()\n",
    "\n",
    "# Calcular el tiempo transcurrido\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Tiempo de entrenamiento: {elapsed_time} segundos\")\n",
    "\n",
    "# Imprimir los mejores parámetros y el mejor rendimiento\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor rendimiento (accuracy):\", grid_search.best_score_)\n",
    "\n",
    "# Obtener el mejor clasificador entrenado\n",
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = best_classifier.predict(X_test_pca)\n",
    "\n",
    "# Evaluar el rendimiento en el conjunto de test\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on test set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec476161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los parámetros y los valores a probar\n",
    "param_grid = {'C': [0.1, 1], \n",
    "              'kernel': ['linear', 'rbf'], \n",
    "              'gamma': [0.1, 1]}\n",
    "\n",
    "# Inicializar el clasificador  SVM\n",
    "svm_classifier = SVC()  \n",
    "\n",
    "# Inicializar GridSearchCV con el clasificador y los parámetros a probar\n",
    "grid_search = GridSearchCV(estimator=svm_classifier, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Iniciar el temporizador antes de entrenar el modelo\n",
    "start_time = time.time()\n",
    "\n",
    "# Realizar la búsqueda de cuadrícula en los datos\n",
    "grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "# Detener el temporizador después de entrenar el modelo\n",
    "end_time = time.time()\n",
    "\n",
    "# Calcular el tiempo transcurrido\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Tiempo de entrenamiento: {elapsed_time} segundos\")\n",
    "\n",
    "# Imprimir los mejores parámetros y el mejor rendimiento\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor rendimiento (accuracy):\", grid_search.best_score_)\n",
    "\n",
    "# Obtener el mejor clasificador entrenado\n",
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = best_classifier.predict(X_test_pca)\n",
    "\n",
    "# Evaluar el rendimiento en el conjunto de test\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on test set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55529130",
   "metadata": {},
   "source": [
    "## Experiment 3\n",
    "\n",
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e1326e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89fdbbd4",
   "metadata": {},
   "source": [
    "## Experiment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eb72c7",
   "metadata": {},
   "source": [
    "HOP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf659b1c",
   "metadata": {},
   "source": [
    "# Anàlisi dels resultats {#analisi}\n",
    "\n",
    "asdasdasdasd m,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467d3373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uib",
   "language": "python",
   "name": "uib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
